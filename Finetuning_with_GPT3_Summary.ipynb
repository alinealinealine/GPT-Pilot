{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26909cf3501d473fac732052b754e782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c04be4b7edf431e939e0090974904eb",
              "IPY_MODEL_73847f3a0aa3477280a91937432515a6"
            ],
            "layout": "IPY_MODEL_7e14a9724407486785d081e79f5c987a"
          }
        },
        "9c04be4b7edf431e939e0090974904eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31f90b42216243a18a3b2798197921ff",
            "placeholder": "​",
            "style": "IPY_MODEL_c70bc73b39364171b921d47d8a89cf50",
            "value": "2.918 MB of 2.918 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "73847f3a0aa3477280a91937432515a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e8dd2113fb4a4182301c830d36953f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_006d7cf14f8749189af634ea95b17dc6",
            "value": 1
          }
        },
        "7e14a9724407486785d081e79f5c987a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f90b42216243a18a3b2798197921ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c70bc73b39364171b921d47d8a89cf50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20e8dd2113fb4a4182301c830d36953f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "006d7cf14f8749189af634ea95b17dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinealinealine/GPT-Pilot/blob/main/Finetuning_with_GPT3_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune GPT-3 for AIMM narrative ex-ante\n",
        "\n",
        "OpenAI's GPT-3 is a natural language model trained on large set of training data. It can be used for various tasks, including to generate data. \n",
        "\n",
        "However, the model is generalist in nature and thus, not fit for specialised tasks in its original or vaniall version. However, will a bit of finetuning it can be used for more specialised tasks such as generating AIMM text. \n",
        "\n",
        "The fine-tuning happens via OpenAI's API to fine tune GPT-3. "
      ],
      "metadata": {
        "id": "IKvXNTD4z6hW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing dependencies and libraries"
      ],
      "metadata": {
        "id": "Ok-vp7KIzqtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FABh1rfFM4Lj",
        "outputId": "470260ff-f99b-43ba-c08b-d890050c5384"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sm4C8Csy9Uo",
        "outputId": "bdf171e2-6476-42ce-9d5c-bf57fd583d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "x48qUFw30-NU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entering API Credentials\n",
        "openai.api_key_path = \"./api.txt\""
      ],
      "metadata": {
        "id": "b87W6_B11Wvv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Prepration\n",
        "\n",
        "The dataset was processed in R by scrapping relevant documents and cleaning it into the JSON format required to finetune the mdoel. The dataset are split based on sector and portion of AIMM narrative it is expected to generate. \n",
        "\n",
        "1. Sector:\n",
        "  1. FIG\n",
        "  2. MAS\n",
        "  3. CDF\n",
        "  4. INR\n",
        "2. Section of AIMM narrative\n",
        "  1. Project narrative\n",
        "  2. Market narrative \n",
        "  3. Indicators\n",
        "\n",
        "In addition different variation of prompts are also explored - creating different models. \n",
        "\n",
        "## Model naming convention\n",
        "\n",
        "In order to keep track of the models they are to be named using the following convention: \"SSS-IN-GEN-XXXX\"\n",
        "* SSS: Refers to Sector of the model's focus: FIG, MAS,CDF, INR or ALL for sector agnostic model\n",
        "* IN: Refers to model input, can be BP for Board Papers and GE for Generic documents\n",
        "* GEN: Refers to which section the model is trying to generate. Can be one of the following:\n",
        "  * PRO: Project narrative\n",
        "  * MAR: Market narrative\n",
        "  * IND: Indicators\n",
        "* XXXX: Refers to the number of the model - as various models might be created to accomodate various prompts. This can also be alpha numeric.\n",
        "\n",
        "### Models trained so far\n",
        "1. FIG-BP-PRO-0001: Uses AIMM summary as prompt and project narrative as completiton. Only focuses on FIG projects for training (~300 samples).\n",
        "2. FIG-BP-MAR-0001: Uses AIMM summary as prompt and market narrative as completiton. Only focuses on FIG projects for training (~300 samples).\n",
        "3. ALL-BP-PRO-0001: Uses project description as prompt and project narrative as completiton. Only focuses on ALL sectors for training (~700 samples).\n",
        "4. ALL-BP-MAR-0001: Uses project description as prompt and market narrative as completiton. Only focuses on ALL sectors for training (~700 samples).\n"
      ],
      "metadata": {
        "id": "CFHJWRAXoOcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = 'ALL-BP-SUM'\n",
        "model_name = project_name+'-0001'"
      ],
      "metadata": {
        "id": "8wBYzA_hCm8p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning \n",
        "\n",
        "Fine tuning involves the following steps:\n",
        "1. Preparing the dataset: Datset is here split into training and validation sets. Before the split - the prompts are also shared with OpenAI to see if they are aligned with the requirements for finetuning.\n",
        "2. FineTuning: This is where the split datasets are shared with OpenAI for finetuning of the GPT model. The final model is saved and can be accessed both here and on OpenAI playground.  \n",
        "\n",
        "## Preping the dataset"
      ],
      "metadata": {
        "id": "li0JRCSo6ISg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a job for splitting dataset\n",
        "run = wandb.init(project=project_name, job_type='split dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "KiHs1hwP7OqG",
        "outputId": "59d76d9e-c938-4e90-cb3e-f4897ff7a33c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230309_212746-9sx7nfje</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cdi/ALL-BP-SUM/runs/9sx7nfje' target=\"_blank\">helpful-sponge-1</a></strong> to <a href='https://wandb.ai/cdi/ALL-BP-SUM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cdi/ALL-BP-SUM' target=\"_blank\">https://wandb.ai/cdi/ALL-BP-SUM</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cdi/ALL-BP-SUM/runs/9sx7nfje' target=\"_blank\">https://wandb.ai/cdi/ALL-BP-SUM/runs/9sx7nfje</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download full dataset\n",
        "dataset_path = \"./\"+model_name+\".json\""
      ],
      "metadata": {
        "id": "ZxedbhgI7Pg7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head $dataset_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_nHuJzL8HL7",
        "outputId": "de92797f-d4ec-4a66-940c-c4841961bfd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"prompt\":\"The proposed project consists of an equity investment of up to USD30 million AfricInvest IV LLC ('AF IV' or the 'Fund'), a generalist, closed-end private equity fund domiciled in Mauritius with a target size of USD500 million. Fund will invest in mid-market growth capital transactions in Africa. The Project is in IFC sector P-BA - Growth Equity Fund and in Africa Region.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary Summary: The Project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Good, based on the AIMM score of 45. On an unadjusted basis (i.e. without likelihood factor), the full potential AIMM score could reach 70. The Project will focus on enhancing the provision of private equity for mid-cap companies across Africa; AfricInvest has a long and positive track record of supporting businesses based in countries with very limited exposure to private equity investments, for example in Tunisia, Algeria and Botswana, and it is expected that approx. 60 percent of investees will be in IDA countries (approx. 50 percent IDA excl. Nigeria and Kenya). The fund manager has a sound and tested value creation strategy that focuses on regional expansion of portfolio companies, recognizing that the ability of the fund manager to grow investees in this case is particularly affected by the complexities typical of the geographies where investee companies operate. Beyond the project, IFC’s continued support of AfricInvest is expected to send a positive signal and demonstrate the sustainability of PE markets in the region. Africinvest IV will mark an evolution for this fund manager to a strategy focusing on increased fund size and a more complex market segment, and AfricInvest’s continued ability to successfully raise funding is expected to remain an important signal in ensuring that PE markets in the region do not regress. However, given the track record of past interventions in Africa (including previous AfricInvest funds) and recognizing the continued reliance of the fund on DFI support, AfricInvest IV is expected to only moderately deepen the region’s PE markets.\\n[END]\"}\n",
            "{\"prompt\":\"IFC proposes an equity investment of up to US$20 million into SPE AIF I L.P (the Fund), alongside a US$20 million co-investment envelope. The Fund is targeting US$200 million of commitments to pursue growth capital investments in small to mid-cap companies in North Africa. The Project is in IFC sector P-BA - Growth Equity Fund and in Middle East Region.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary Summary: The Project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Good, based on the AIMM score of 50. On an unadjusted basis (i.e. without likelihood factor), the full potential AIMM score could reach 70. The most significant, expected project-level outcomes include (i) the Fund providing access to private equity capital to companies in Morocco, Tunisia and Egypt, where access to equity is constrained for mid-cap businesses; and (ii) increased investee growth, through the fund’s local teams, who focus on strengthening corporate governance, growing product lines, expanding the customer base, and expanding regionally. Beyond the project, the most significant contribution of this intervention is expected to derive from SPE Capital attracting new private institutional investors and LPs to North Africa, thus contributing to deepening capital markets, with the view of retaining these LPs in the region beyond this fund and possibly with other fund managers.\\n[END]\"}\n",
            "{\"prompt\":\"Mekong Enterprise Fund IV Limited Partnership ('the Fund'), a Cayman Islands exempted limited partnership, is a private equity ('PE') fund seeking $200 million in capital commitments to build a portfolio of equity investments in middle market, growth-oriented companies in Vietnam. The Project is in IFC sector P-BA - Growth Equity Fund and in Vietnam.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary: The Project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Satisfactory, based on the AIMM score of 40. On an unadjusted basis (i.e., without likelihood factor), the full potential AIMM score could reach 46, Good. The most significant, expected project-level outcomes include; (i) providing access to 8 to 10 mid-cap companies focused on consumer-driven businesses in Vietnam, a market where access to private equity is limited, especially for mid-cap companies; and (ii) increased investee growth through the Fund’s focus on improving investee governance, driving growth focusing on digital adaptation or transformation, and opening up several viable paths for exit. Beyond the project, in the context of a PE market where country-focused domestic managers are very limited, and which has seen intermittent activity and has not deepened in the past ten years, MPEF IV is expected to send a signal of confidence through the demonstration of the viability of a domestic country-focused PE business model in Vietnam. The emergence and success of a few local country-focused funds, including MPEF III, which was backed by IFC, have not yet succeeded in driving further market changes, demonstrating the complexity and time required to create a sustainable PE ecosystem in the country. At this stage it is not expected that this investment alone, while representing an important addition to the market, will be able to substantially alter the local PE market.\\n[END]\"}\n",
            "{\"prompt\":\"IFC proposes an equity investment of up to US$ 10 million into India Alternatives Private Equity Fund II (the Fund), a scheme of India Alternatives Private Equity Trust ('Trust'). A We-Fi commitment of up to US$ 0.5 million is also being considered. The Fund is targeting US$ 70 million of commitments to pursue growth capital investments in small to mid-cap companies in India. The Project is in IFC sector P-BA - Growth Equity Fund and in India.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary: The Project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Satisfactory, based on the AIMM score of 35. On an unadjusted basis (i.e., without likelihood factor), the full potential AIMM score could reach 46 (Good). The most significant, expected project-level outcomes include: (i) increased access to private equity capital for SMEs and small to mid-cap companies, which typically seek growth capital, especially at times of major economic uncertainty related to Covid-19; (ii) increased investee growth, which will be supported by India Alternatives’ value creation strategies. As a first-time woman-led local fund manager, India Alternatives has demonstrated the ability to support successful small businesses in the first fund, owing to deep local knowledge and networks. Beyond the project, the investment will increase inclusiveness of the domestic Indian PE market by promoting inclusive business models and practices. India, on par with MENA, lags all the other emerging markets in terms of gender diversity in the PE industry; meanwhile, female PE fund managers are instrumental in increasing inclusiveness in business practices and in encouraging female entrepreneurship more broadly (e.g. by leading by example, and by providing gender-lens outreach activities). IFC’s support to this Fund, which is one of two in India led by a woman [, including potentially with a blended finance contribution from We-Fi,] can help disseminate inclusive practices in the PE industry, which in turn promote entrepreneurship practices that are inclusive of women across investees and in other industries, through gender-related outreach and activities.\\n[END]\"}\n",
            "{\"prompt\":\"The proposed investment is for up to US$25 million in Navis CLMV Co-Investment Fund, L.P. ('the Fund' or 'the CLMV Fund'), a US$150 million (target) buyout fund investing into Cambodia, Laos, Myanmar and Vietnam ('CLMV'). The Fund will be managed by Navis Capital Partners Limited or an affiliate thereof ('Navis') and will co-invest alongside Navis Asia Fund VIII, L.P. and its parallel funds ('Navis VIII') in investments in the CLMV markets. The Project is in IFC sector P-BA - Growth Equity Fund and in East Asia and Pacific Region.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary: The Project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Good, based on the AIMM score of 48. On an unadjusted basis (i.e., without likelihood factor), the full potential AIMM score could reach 64. The most significant, expected project-level outcomes include: (i) providing access to 6 to 8 mid-cap companies, including on the larger end of the mid cap segment, focused on businesses in CLMV countries, especially in the IDA countries (CLM), where access to PE or traditional sources of capital is extremely limited; and (ii) increased investee growth, through the Fund manager’s focus on improving operational efficiency and corporate best practices. PE markets in the CLM region are nascent or non-existent, characterized by marginal activity, lacking an equity ecosystem and large or established fund managers. The entry in the region of an international Fund Manager such as Navis with a US$450 million dedicated PE vehicle represents a first step towards deepening the PE market in these countries. This project is expected to catalyze a number of market changing impacts: it deepens the existing markets by providing an avenue for smaller fund managers to exit, i.e. for businesses which have grown to a certain size to change hands to more professional fund managers, adding market resilience; and, given the co-investment by Navis VIII alongside Navis CLMV, the LPs of Navis VIII will be exposed to and gain familiarity with the CLMV region, further integrating these countries’ capital markets, and potentially establishing ties in these markets for the medium to long term. Recognizing that there remain obstacles for the market to develop further, Navis-CLMV setting foot in CLM is expected to strengthen the structure and increase activity in this market in the short to medium term.\\n[END]\"}\n",
            "{\"prompt\":\"Founded in 2017, SeeTree Systems Limited ('SeeTree', or 'Company') is an Israel based high-tech start-up that provides analytics services to growers of permanent crops. It is headquartered in Tel Aviv, Israel with customers currently across California (USA), Brazil and pilots in South Africa, Chile and Indonesia.The core product of SeeTree is developing precision agriculture solution at macro level grove and micro tree level data. Customers have the option of choosing from a basic package which gives them basic view of tree health, and layer on additional features, such as early disease detection and yield improvement recommendations. SeeTree uses all-terrain vehicles (ATVs), drone technology and on the ground teams to collect and ground-truth data.In addition to its headquarters in Israel, where are based the management and operational teams, Research and Development (R&D), and the 'Intelligence Desks' which are the teams responsible to conduct the analytical services provided by the company, SeeTree has a R&D Center in Ukraine performing engineering and software development, and two subsidiaries in the United States and Brazil running field operations including data-collection and customer management. Going forward, the company plans to open new markets and establish new subsidiaries at new locations such as Europe and Southeast Asia. IFC is considering an equity investment of up to US$8 million to be used for the Company's expansion plans The Project is in IFC sector A-AF - Fruits and Vegetables and in Israel.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary The project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Satisfactory, based on an AIMM score of 35. On an unadjusted basis (i.e. without likelihood factor), the full AIMM score could reach 46 (Good). The most significant expected Project-level Outcomes are derived from improved productivity of permanent crops in Brazil, achieved by deploying at scale an AI technology that measures the health of individual trees, thereby significantly increasing the percentage of healthy trees. These outcomes have the potential to result into higher income for growers as the data analytics allow growers to prepare the right marketing strategy based on size and volume of products. Beyond the Project, the main sources of expected Market Creation outcomes are derived from the potential to maintain the competitiveness of the Brazilian permanent crop sector, which is generally developed, by stimulating further adoption of precision agriculture technologies via demonstration and replication channels. A successful expansion by the Company is expected to enable the entry of similar agriculture technology companies and promote adoption of the technology by growers in Brazil.\\n[END]\"}\n",
            "{\"prompt\":\"SeeTree Systems Limited ('SeeTree', or 'Company') is an Israel based high-tech company that provides analytics services to growers of permanent crops. The Company was founded in 2017 and is headquartered in Tel Aviv, Israel with customers currently across California (USA), Brazil and South Africa, and pilots in Argentina and Indonesia. The proposed investment will support the Company's expansion plans. The Project is in IFC sector A-AF - Fruits and Vegetables and in Israel.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary The project has an Anticipated Impact Measurement and Monitoring (AIMM) rating of Satisfactory, based on an AIMM score of 35. On an unadjusted basis (i.e. without likelihood factor), the full AIMM score could reach 46 (Good). The most significant expected Project-level Outcomes are derived from improved productivity of permanent crops in Brazil, achieved by deploying at scale an AI technology that measures the health of individual trees, thereby significantly increasing the percentage of healthy trees. These outcomes have the potential to result into higher income for growers as the data analytics allow growers to prepare the right marketing strategy based on size and volume of products. Beyond the Project, the main sources of expected Market Creation outcomes are derived from the potential to maintain the competitiveness of the Brazilian permanent crop sector, which is generally developed, by stimulating further adoption of precision agriculture technologies via demonstration and replication channels. A successful expansion by the Company is expected to enable the entry of similar agriculture technology companies and promote adoption of the technology by growers in Brazil.\\n[END]\"}\n",
            "{\"prompt\":\"Bolt was launched in Estonia in 2013 and is a leading global mobility platform, operating in over 200 cities across more than 40 countries, with a focus on Africa and Central and Eastern Europe ('CEE'). The Company's three core offerings include: (i) Ridehailing: on-demand ride booking of cars, motorcycles, and tuktuks; (ii) E-mobility rentals: dockless electric scooter rentals and e-bikes; and (iii) Delivery: on-demand food, grocery, and business deliveries. The Company has more than 50 million customers and 1.5 million drivers globally. As of 2019, some of the platform's largest markets by number of rides include: South Africa, Nigeria, Poland, Kenya, and Azerbaijan.IFC is considering a EUR 20 million investment in Bolt in the form of a convertible note. The proceeds of the financing are expected to help support the Company as it: (i) expands further into Tier 2 and 3 cities in Africa and CEE; (ii) grows its food delivery product, and (iii) introduces financial service products in Africa and CEE. The Project is in IFC sector E-BD - Other Support Activities for Transportation (Grain Terminals, Cargo Terminals, Airport Operations) and in Africa Region.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary The project has an Anticipated Impact Measurement and Monitoring (“AIMM”) rating of Good, based on an AIMM score of 53. On an unadjusted basis (i.e. without likelihood factor), the full AIMM score could reach 70 (Excellent). The most significant expected Project-level Outcomes are derived from increased self-employment for workers across emerging markets in Africa and Central and Eastern Europe, especially women and individuals from low-income backgrounds. This outcome is expected to be achieved by deploying at scale, mainly in tier 2 and 3 cities, an online platform that provides micro-entrepreneurship opportunities to individuals seeking to earn a supplementary income by moving people and goods across locations. These workers will also benefit from trainings in financial literacy and access to financial services such as loans or vehicle leasing. Such expansion is also expected to increase access to affordable urban mobility services for riders, with greater price transparency and improved convenience and safety. Beyond the Project, the main sources of expected Market Creation outcomes are derived from the potential to maintain the competitiveness of the emerging mobility sector across the target markets (SSA and ECA), and especially in tier 2 and 3 cities in Nigeria, South Africa and Ukraine, by enabling increased access to and usage of online mobility services beyond the Company via competition channels. A successful expansion by the Company is expected to induce competitors to up their game through entry into tier 2 and 3 cities or deeper expansion into existing markets by introducing innovative services for drivers.\\n[END]\"}\n",
            "{\"prompt\":\"Bolt Technology OU ('Bolt' or the 'Company') is a global ride-hailing company, offering mobility, food, and delivery services through a digital platform. The Company was established in 2013 in Estonia and has since expanded its operations to more than 35 countries and 200 cities globally. The Project is in IFC sector E-BD - Other Support Activities for Transportation (Grain Terminals, Cargo Terminals, Airport Operations) and in Africa Region.\\n\\n###\\n\\n\",\"completion\":\" DEVELOPMENT IMPACT Summary The project has an Anticipated Impact Measurement and Monitoring (“AIMM”) rating of Good, based on an AIMM score of 53. On an unadjusted basis (i.e. without likelihood factor), the full AIMM score could reach 70 (Excellent). The most significant expected Project-level Outcomes are derived from increased self-employment for workers across emerging markets in Africa and Central and Eastern Europe, especially women and individuals from low-income backgrounds. This outcome is expected to be achieved by deploying at scale, mainly in tier 2 and 3 cities, an online platform that provides micro-entrepreneurship opportunities to individuals seeking to earn a supplementary income by moving people and goods across locations. These workers will also benefit from trainings in financial literacy and access to financial services such as loans or vehicle leasing. Such expansion is also expected to increase access to affordable urban mobility services for riders, with greater price transparency and improved convenience and safety. Beyond the Project, the main sources of expected Market Creation outcomes are derived from the potential to maintain the competitiveness of the emerging mobility sector across the target markets (SSA and ECA), and especially in tier 2 and 3 cities in Nigeria, South Africa and Ukraine, by enabling increased access to and usage of online mobility services beyond the Company via competition channels. A successful expansion by the Company is expected to induce competitors to up their game through entry into tier 2 and 3 cities or deeper expansion into existing markets by introducing innovative services for drivers.\\n[END]\"}\n",
            "{\"prompt\":\"IFC is considering an investment of up to US$3 million in Microtraction Fund II (the Fund') through the Startup Catalyst Program. Microtraction Fund II is a $15 million seed stage fund focused on pre-seed and seed stage investments in tech and tech-enabled businesses in Sub Saharan Africa.The Fund will be supported by the Blended Finance Facility (BFF) of the IDA18 IFC-MIGA Private Sector Window (IDA PSW), created by the Word Bank Group to catalyze private sector investment in IDA countries, with a focus on fragile and conflict-affected states. The Project is in IFC sector P-BB - Venture Capital Fund and in Nigeria.\\n\\n###\\n\\n\",\"completion\":\" Development Impact ISC eligible and AIMM score. This project falls under the Startup Catalyst Envelope Expansion Program (Project ID: 42736) and is aligned to the development impact rationale set out in the Board Paper dated May 18 2020. This project is therefore assigned an ex-ante AIMM score of 61 (Good). The full potential, without the likelihood adjustment is 88 (Excellent).\\n[END]\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f $dataset_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcbedLhr8LNz",
        "outputId": "fe4e27c2-80d4-40bf-88eb-7da8b93a9bb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your JSON file appears to be in a JSONL format. Your file will be converted to JSONL format\n",
            "- Your file contains 735 prompt-completion pairs\n",
            "- There are 3 examples that are very long. These are rows: [358, 542, 720]\n",
            "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
            "- All prompts end with suffix `.\\n\\n###\\n\\n`\n",
            "- All completions end with suffix `\\n[END]`\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `JSON` will be converted to `JSONL`\n",
            "- [Recommended] Remove 3 long examples [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `./ALL-BP-SUM-0001_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"./ALL-BP-SUM-0001_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `.\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n[END]\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 31.62 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"./\"+model_name+\"_prepared.jsonl\"\n",
        "# check number of samples\n",
        "!wc -l $dataset_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti7EhJ-r8R-D",
        "outputId": "a11aca88-ad06-4d5e-e79e-a008d3970392"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "732 ./ALL-BP-SUM-0001_prepared.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting it into training and testing set randomly with 25% going to testing set. \n",
        "* Training Set = 75% \n",
        "* Validation Set = 25% \n",
        "\n",
        "Also, logging the files into W&B for recordkeeping. "
      ],
      "metadata": {
        "id": "lb_lbts_pIDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(dataset_path, orient='records', lines=True)\n",
        "df_train, df_test = train_test_split(df,test_size = 0.25,random_state = 42, shuffle = False)\n",
        "df_train.to_json(\"./\"+model_name+\"_train.jsonl\", orient='records', lines=True)\n",
        "df_test.to_json(\"./\"+model_name+\"_test.jsonl\", orient='records', lines=True)\n",
        "\n",
        "#Logging the files and tables into W&B \n",
        "table_train = wandb.Table(dataframe=df_train)\n",
        "table_valid = wandb.Table(dataframe=df_test)\n",
        "\n",
        "# Create artifacts\n",
        "artifact_train = wandb.Artifact(model_name+\"_train.jsonl\", type='training_files', metadata={'samples': df_train.shape[0]})\n",
        "artifact_train.add_file(model_name+\"_train.jsonl\")\n",
        "artifact_train.add(table_train, model_name+\"_train.jsonl\")\n",
        "\n",
        "artifact_valid = wandb.Artifact(model_name+\"_test.jsonl\", type='validation_files', metadata={'samples': df_test.shape[0]})\n",
        "artifact_valid.add_file(model_name+\"_test.jsonl\")\n",
        "artifact_valid.add(table_valid, model_name+\"_test.jsonl\")\n",
        "\n",
        "# Log files\n",
        "run.log_artifact(artifact_train)\n",
        "run.log_artifact(artifact_valid)"
      ],
      "metadata": {
        "id": "58mTu1PG8UfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a136019-c1fa-490c-a945-6fc5bbef7b2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_artifacts.Artifact at 0x7f8849ff3af0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Closing our dataprep run"
      ],
      "metadata": {
        "id": "wL8pKbh0qqXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep entity for reference of artifact later \n",
        "entity = wandb.run.entity\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "26909cf3501d473fac732052b754e782",
            "9c04be4b7edf431e939e0090974904eb",
            "73847f3a0aa3477280a91937432515a6",
            "7e14a9724407486785d081e79f5c987a",
            "31f90b42216243a18a3b2798197921ff",
            "c70bc73b39364171b921d47d8a89cf50",
            "20e8dd2113fb4a4182301c830d36953f",
            "006d7cf14f8749189af634ea95b17dc6"
          ]
        },
        "id": "vkXaYc40qsKf",
        "outputId": "f1cf0a2a-1254-4c09-c519-0d2c7006b0f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='2.918 MB of 2.918 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26909cf3501d473fac732052b754e782"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">helpful-sponge-1</strong> at: <a href='https://wandb.ai/cdi/ALL-BP-SUM/runs/9sx7nfje' target=\"_blank\">https://wandb.ai/cdi/ALL-BP-SUM/runs/9sx7nfje</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230309_212746-9sx7nfje/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning the model\n"
      ],
      "metadata": {
        "id": "20f5YU5erAgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = \"./\"+model_name+\"_train.jsonl\"\n",
        "valid_file = \"./\"+model_name+\"_test.jsonl\""
      ],
      "metadata": {
        "id": "A51VozQnsD5G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Hyper parameters: \n",
        "\n",
        "Using the default hyper parameters by OpenAI, replacing model with Divinci 003."
      ],
      "metadata": {
        "id": "AytRIGhisVq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining hyper parameters (using the default ones)\n",
        "model = 'davinci'  # using the best model : davinci\n",
        "n_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate_multiplier = 0.1\n",
        "prompt_loss_weight = 0.1"
      ],
      "metadata": {
        "id": "9zaCtwX_r2IQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"API-KEY\""
      ],
      "metadata": {
        "id": "E2yw5YFUxW1x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create \\\n",
        "    -t $train_file \\\n",
        "    -v $valid_file \\\n",
        "    -m $model \\\n",
        "    --n_epochs $n_epochs \\\n",
        "    --batch_size $batch_size \\\n",
        "    --learning_rate_multiplier $learning_rate_multiplier \\\n",
        "    --prompt_loss_weight $prompt_loss_weight \\\n",
        "    --suffix $model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5etp9msr8q4",
        "outputId": "7c96e0e2-c959-4836-c76b-86781a20808f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/1.09M [00:00<?, ?it/s]\rUpload progress: 100% 1.09M/1.09M [00:00<00:00, 426Mit/s]\n",
            "Uploaded file from ./ALL-BP-SUM-0001_train.jsonl: file-wygPRDcIomBpvm9nTIc54HTx\n",
            "Upload progress: 100% 446k/446k [00:00<00:00, 485Mit/s]\n",
            "Uploaded file from ./ALL-BP-SUM-0001_test.jsonl: file-InshcNxiJSsWvJc9d9rGzZHu\n",
            "Created fine-tune: ft-qtN3QMqxtKlCJ7mqY47qhWZn\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-03-09 21:30:41] Created fine-tune: ft-qtN3QMqxtKlCJ7mqY47qhWZn\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-qtN3QMqxtKlCJ7mqY47qhWZn\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-qtN3QMqxtKlCJ7mqY47qhWZn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMfui19k0vkt",
        "outputId": "1f82ffd6-021a-47a3-bdb6-f48a6434fb4f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: openai: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Syncing FineTune Jobs to W&B\n",
        " \n",
        " Logging Fine Tune with W&B to use later\n",
        " "
      ],
      "metadata": {
        "id": "ZkzTIoNgsjxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai wandb sync\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "KuZjW0Jqsro1",
        "outputId": "1763bb26-796b-4f7b-9e2e-1903fa5b4c98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: openai: command not found\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-924f6801a1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openai wandb sync'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
          ]
        }
      ]
    }
  ]
}